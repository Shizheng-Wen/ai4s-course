- date: 9/18
  title: >
    Week 1 <strong>Course Introduction</strong> <a href="AISE25Lect1.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/play/f0vxnPqBJjP8fKcrx7qEnbD1ENg9kLxy6_D19hZFTz1qPIu_u6mmFDNujQyvIgItI5d8qzR6EhBivVEp.uj3NhRBr2hA-YGqe?eagerLoadZvaPages=sidemenu.billing.plan_management&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fethz.zoom.us%2Frec%2Fshare%2FGand-InVqT_l0A2NDgQArhoI2o1nynVu7zuXCnlK2DNwb4ldTkO1tGV-tpfoag5u.sGt2HQ-r_eKp1aCE">[recording]</a>

  slides:
  topics:
    - Course syllabus and requirements
    - AI in Science and Engineering
    - Mathematical modeling with PDEs
    - Computational challenges
    - Motivation for AI approaches
  readings:
    - <a href="https://www.nature.com/articles/s41586-023-06221-2">Scientific discovery in the age of artificial intelligence</a> <br/>
    - <a href="https://www.nature.com/articles/s42254-024-00712-5">Neural operators for accelerating scientific simulations and design</a> <br/>
    - <a href="https://www.nature.com/articles/s42254-021-00314-5">Physics-informed machine learning</a> <br/>

- date: 9/25
  title: >
    Week 2 <strong>Introduction to Deep Learning</strong> <a href="AISE25Lect2.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/play/8QIKsLmZDtRTRjwauoXcSsg1ANkAc2D0jc8Munhj2BXFjAyuD3WhKnRuIolqPCSFh7-Pjny3DtIYuBI.5S9x3jgNVCXAJpcw?autoplay=true&startTime=1758780652000">[recording]</a>
  slides:
  topics:
    - Introduction to using deep learning to model physical systems governed by PDEs.
    - Structure of MLPs with layers, weights, biases, and activation functions (sigmoid, tanh, ReLU, etc.).
    - Gradient descent, stochastic gradient descent (SGD), mini-batch SGD
    - Motivation for convolutional neural networks (CNNs) to handle high-dimensional inputs efficiently.


  readings:
    - <a href="https://arxiv.org/abs/1412.6980">Adam:A Method for Stochastic Optimization</a> <br/>
    - <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem"> WIKIPEDIA:Universal approximation theorem</a> <br/>
    - <a href="https://www.nature.com/articles/nature14539"> Deep learning</a> <br/>


- date: 10/2
  title: >
    Week 3 <strong>Introduction to Physics-Informed Neural Networks</strong> <a href="AISE25Lect3.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/play/fN2KHdgdgoIVkc-3JZfDf2BHKxQj58hwAqzkRaoc3aOr0ydN32-CK10sqKfsqJ0LzmbgsEUwi0G4nz4.SbdPCEmJbWFy_9eS?eagerLoadZvaPages=sidemenu.billing.plan_management&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&startTime=1759385427000&componentName=rec-play&originRequestUrl=https%3A%2F%2Fethz.zoom.us%2Frec%2Fshare%2F_yp9-FA_eqb6QU5CQbcLoWy_tuLUyb_3H63yyDNpmLMazLcj8BPe7dYAmqs7FueY.1UVNnzP-eTSAP56_%3FstartTime%3D1759385427000">[recording]</a>
  slides:
  topics:
    - Introduction to Physics-Informed Neural Networks (PINNs).
    - Extending PINNs to reconstruct unknown solutions or parameters from partial measurements.
    - PINNs unify data-driven learning and physics-based modeling, offering flexible, mesh-free solvers for forward and inverse PDE problems.
  readings:
    - <a href="https://www.sciencedirect.com/science/article/pii/S0021999118307125">Physics-informed neural networks A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations</a> <br/>
    - <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/cnm.1640100303">neural-network-based approximations for solving partial differential equations</a> <br/>
    - <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=712178">Artificial Neural Networks for Solving Ordinary and Partial Differential Equations</a> <br/>
    - <a href="https://www.sciencedirect.com/science/article/pii/S0022407321001989">Physics informed neural networks for simulating radiative transfer</a> <br/>


- date: 10/9
  title: >
    Week 4 <strong>PINNs - Theoretical insights</strong> <a href="AISE25Lect4.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/play/kAAePCqakjFVOBbB8YPXMNRlQyUDyWudCl76fLNAa4j21qb9hj2ic2rvMYeqrz_YB4mYu4-GXv7ynLWj.4Ns8mOAcWNosJjKb?autoplay=true&startTime=1759990281000">[recording]</a>
  slides:
  topics:
    - Review of Physics-Informed Neural Networks (PINNs) for solving PDEs.
    - Theoretical analysis of PINN error - relation between training error, PDE residuals, and total approximation error.
    - Conditions ensuring convergence - coercivity, quadrature approximation, and DNN expressivity.
    - Rigorous error bounds for linear and nonlinear PDEs (Kolmogorov, Black-Scholes, Navier-Stokes, Burgers' equation).
    - Gradient descent dynamics and conditioning in PINN training; interpretation via NTK and preconditioning.
    - Practical performance and challenges:successes on smooth PDEs, difficulties on shocks or high-conditioning problems.
    - Overview of acceleration and stabilization techniques (causal learning, hard BCs, multi-stage networks).
  readings:
    - <a href="https://arxiv.org/abs/2106.14473">Error estimates for physics-informed neural networks approximating Kolmogorov PDEs</a> <br/>
    - <a href="https://arxiv.org/abs/2402.10926">Numerical analysis of physics-informed neural networks and related models in physics-informed machine learning</a> <br/>
    - <a href="https://arxiv.org/abs/2104.08938">On the approximation of functions by tanh neural networks</a> <br/>

- date: 10/16
  title: >
    Week 5 <strong>Operator Learning - Introduction</strong> <a href="AISE25Lect5.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/play/PA4-nX5frP8Sx5s1C0wlD784lHqHFNSxzGbzVyTYrg826Hj9ZOWtvsUhbAQvIEwMnda_5ei6Pb8nY35V.8Vk71uTJKFvXtq_5?autoplay=true&startTime=1760595311000">[recording]</a>
  slides:
  topics:
    - Transition from physics-informed learning to data-driven approaches.
    - Introduction to operator learning
    - Parametric PDE learning:deep networks approximating observables for low-dimensional parameterizations.
    - Operator learning:approximating infinite-dimensional mappings from data distributions.
    - Neural Operators generalizing DNNs to function spaces.
    - Fourier Neural Operators (FNOs):convolution in Fourier space, efficient and translation-invariant.
    - Theoretical foundation:universal approximation theorems for FNOs.
    - Practical challenges:bridging continuous operators and discrete numerical data (continuous-discrete equivalence).
  readings:
    - <a href="https://arxiv.org/abs/2108.08481">Neural Operator:Learning Maps Between Function Spaces</a> <br/>
    - <a href="https://arxiv.org/abs/2010.08895">Fourier Neural Operator for Parametric Partial Differential Equations</a> <br/>


- date: 10/23
  title: >
    Week 6 <strong>Operator Learning - FNO</strong> <a href="AISE25Lect6.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/share/ZaluQhiclGWo3ANjPt9Nfy74OZwHYEWfRsK0xkZRIxUc1oDU90TrqOel6KyWHHv8.vDT5OE7mRCbJ1hkb?startTime=1761199538000">[recording]</a>
  slides:
  topics:
    - Continuation of Operator Learning - FNO.
    - Continuous-discrete equivalence and Representation equivalent neural operators (ReNOs).
    - Why CNN and FNO are not ReNO.
  readings:
    - <a href="https://arxiv.org/abs/2305.19913">Representation Equivalent Neural Operators:a Framework for Alias-free Operator Learning</a> <br/>

- date: 10/30
  title: >
    Week 7 <strong>Operator Learning - ReNO</strong> <a href="AISE25Lect7.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/play/a9Aek3di9zlbmSQYmaweAan7ySCkmW5KbTfeUIXK0OjbXIlWaz2u-Xa24foQ7Jo2LZ_ca-3hM7hxibeW.xfP20pFaAuRDviXC?eagerLoadZvaPages=sidemenu.billing.plan_management&isReferralProgramEnabled=false&isReferralProgramAvailable=false&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&startTime=1761808433000&componentName=rec-play&originRequestUrl=https%3A%2F%2Fethz.zoom.us%2Frec%2Fshare%2FirrWFSRiEPTmIIdkHiuWcWf1X7hQwYZSn3QLuYxU74Xs1zu-Ns41KZA2wwspkzzT.pR5-rAh0ibCOvyGm%3FstartTime%3D1761808433000">[recording]</a>
  slides:
  topics:
    - Continuation of Operator Learning - ReNO.
    - Convolutional Neural Operator (CNO), which is constructed to be a ReNO

  readings:
    - <a href="https://arxiv.org/abs/2302.01178">Convolutional Neural Operators for robust and accurate learning of PDEs</a> <br/>

- date: 11/6
  title: >
    Week 8 <strong>Operator Learning - Operator Transformer</strong> <a href="AISE25Lect8.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/play/o2p2CHXAQCVnUH_YDaNDuk4i84p5sXF2tVl4m4uM2mTIYwMdRZ0F2EBzDyzIX2jvaktSlP0W8s6X3N84.WuUyIBg82933aBVu?eagerLoadZvaPages=sidemenu.billing.plan_management&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&startTime=1762413140000&componentName=rec-play&originRequestUrl=https%3A%2F%2Fethz.zoom.us%2Frec%2Fshare%2FSOch6CrwJRcOuzuuP11sPYfQizLbbKudYFK4FesHc_VzafM3SLCB8wwYqwuZAU2q.yuidnV3GRkcqjCTF%3FstartTime%3D1762413140000">[recording]</a>
  slides:
  topics:
    - Transformer architecture and its application to operator learning.
    - Scaling issue for operator learning task.
    - Convolutional Neural Operator (CNO), which is constructed to be a ReNO

  readings:
    - <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> <br/>
    - <a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words:Transformers for Image Recognition at Scale</a> <br/>
    - <a href="https://arxiv.org/abs/2405.19101">Poseidon:Efficient Foundation Models for PDEs</a> <br/>

- date: 11/13
  title: >
    Week 9 <strong>Operator Learning - Graph-based Model</strong> <a href="AISE25Lect9.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/play/FibJ0q7wYYkjOyIjcQLtz8-487OpDyDP2meRZUJkWNikVpz0Xm859YNgPGAhwNCK9LxnCQIwdJ_Otbqv.RaI9j1vz4NO7vDi2?eagerLoadZvaPages=sidemenu.billing.plan_management&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&startTime=1763018149000&componentName=rec-play&originRequestUrl=https%3A%2F%2Fethz.zoom.us%2Frec%2Fshare%2FmY2L0VW3B0yI2Yg3rwimlUAfYZYpTghynv8sc9Pd_Zt37CNxwimBxnUwSkOC8uuD.PCOe-VEa70db0PMe%3FstartTime%3D1763018149000">[recording]</a>
  slides:
  topics:
    - Graph-based model for operator learning.

  readings:
    - <a href="https://arxiv.org/abs/1704.01212">Neural Message Passing for Quantum Chemistry</a> <br/>
    - <a href="https://arxiv.org/abs/2501.19205">RIGNO:A Graph-based framework for robust and accurate operator learning for PDEs on arbitrary domains</a> <br/>

- date: 11/20
  title: >
    Week 10 <strong>Operator Learning - GAOT</strong> <a href="AISE25Lect10.pdf">[slides]</a> <a href="https://ethz.zoom.us/rec/play/kep06HEchxzegb1Xs8zg4oTpdxNM4mD6uQNy8A50cQtoVfWFVdzWywMFkpwyK8cUl4vSERuiSny8nm49.xWOA5z-KrhTRKVk7?eagerLoadZvaPages=sidemenu.billing.plan_management&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&startTime=1763622637000&componentName=rec-play&originRequestUrl=https%3A%2F%2Fethz.zoom.us%2Frec%2Fshare%2FaaUiKKbPCzQy-t7mFpzNcHP4hLa7Eh8wEdCm602uK4XOcbqpNw9F-LUX32VJ2LNm.F8k-5Zs8ehc2jE2S%3FstartTime%3D1763622637000">[recording]</a>
  slides:
  topics:
    - Efficiency-Accuracy Trade-off in Operator Learning.
    - Geometry Aware Operator Transformer (GAOT) for operator learning.
    - Operator Learning for industrial-scale 3D datasets.

  readings:
    - <a href="https://arxiv.org/abs/2505.18781">Geometry Aware Operator Transformer as an Efficient and Accurate Neural Surrogate for PDEs on Arbitrary Domains</a> <br/>
    - <a href="https://arxiv.org/abs/2309.00583">Geometry-Informed Neural Operator for Large-Scale 3D PDEs</a> <br/>
    - <a href="https://arxiv.org/abs/2402.02366">Transolver:A Fast Transformer Solver for PDEs on General Geometries</a> <br/>
    - <a href="https://arxiv.org/abs/2406.09624">DrivAerNet++:A Large-Scale Multimodal Car Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks</a> <br/>
    - <a href="https://arxiv.org/abs/2408.11969">DrivAerML:High-Fidelity Computational Fluid Dynamics Dataset for Road-Car External Aerodynamics</a> <br/>



- date: 11/27
  title: >
    Week 11 <strong>Generative model for PDE - GenCFD</strong> <a href="AISE25Lect11.pdf">[slides]</a>
  slides:
  topics:
    - Diffusion-based generative models for PDEs with chaotic multiscale solutions.
    - Insensitivity of neural networks to the input.

  readings:
    - <a href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a> <br/>
    - <a href="https://arxiv.org/abs/2409.18359">Generative AI for fast and accurate statistical computation of fluids</a> <br/>
    - <a href="https://arxiv.org/abs/2506.03111">Rectified Flows for Fast Multiscale Fluid Flow Modeling</a> <br/>



- date: 12/4

- date: 12/11

- date: 12/18